{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUiAiuvsn3yN"
   },
   "source": [
    "# 1. Loading the Data from Google Drive\n",
    "---\n",
    "### 1.1 Mount Dataset\n",
    "\n",
    "Mount the drive and extract the dataset from images separated into corresponding folders\n",
    "\n",
    "The mounting of the drive is only necessary if the notebook is run on Google Colab instead of locally\n",
    "\n",
    "The folder is divided into:\n",
    "1. Test Folder\n",
    "  * With Mask Folder\n",
    "  * Without Mask Folder\n",
    "2. Train Folder\n",
    "  * With Mask Folder\n",
    "  * Without Mask Folder\n",
    "2. Validation Folder\n",
    "  * With Mask Folder\n",
    "  * Without Mask Folder\n",
    "\n",
    "---\n",
    "### 1.2 Import Modules\n",
    "\n",
    "All required modules are also imported after \n",
    "\n",
    "These modules are:\n",
    "  * Numpy\n",
    "  * Matplotlib.pyplot\n",
    "  * Seaborn\n",
    "  * Tensorflow\n",
    "  * Keras \n",
    "  * Scikit-Learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2JM0qOdYou9i",
    "outputId": "62280fc5-8177-4eae-f65d-5e8739211239",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1.1 \n",
    "# Mounting to drive\n",
    "# This step is only necessary if the notebook is run on Google Colab instead of locally\n",
    "\n",
    "from google.colab import drive \n",
    "\n",
    "drive.mount(\"/content/gdrive\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H0NsaJRfo81U"
   },
   "outputs": [],
   "source": [
    "# 1.2\n",
    "# Import needed modules\n",
    "\n",
    "# Basic packages needed for data analysis, visualization and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Mainly Tensorflow packages for data preprocessing\n",
    "from PIL import Image \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    "# Mainly Tensorflow.keras layers needed to build the Convolutional Neural Network (CNN)\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras import Sequential, regularizers\n",
    "\n",
    "# Mainly functions to load from saved checkpoints\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Mainly Tensorflow modules that help to optimize and fine-tune the CNN models better\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from sklearn.model_selection import KFold, train_test_split \n",
    "from math import ceil\n",
    "\n",
    "# Mainly metrics to assess the CNN's performance\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0jPV8cbo3GW"
   },
   "source": [
    "# 2. Preprocessing the data and preparing the CNN model\n",
    "\n",
    "___\n",
    "\n",
    "### 2.1 Prepare ImageDataGenerator\n",
    "Create an ImageDataGenerator instance for data augmentation\n",
    "\n",
    "Considering the rotation, width and height shift, brightness, shear, zoom and horizontal flipping to mimic the possible real-world data the model would face\n",
    "\n",
    "Diversifies the dataset to let the model be trained on a larger and more diverse set of images\n",
    "\n",
    "___\n",
    "\n",
    "### 2.2 Construct CNN Model\n",
    "The model's architecture is mainly a result of extensive experimentation, with AlexNet/ZFNet as inspirations of the starting point architecture\n",
    "\n",
    "The activation function for the hidden layers would be ReLU whereas Sigmoid would be applied to the output layer of a single neuron\n",
    "\n",
    "The dense layers would have dropout regularization and L2 weight regularization applied \n",
    "\n",
    "The optimizer used is Adam, which gives an adaptive learning rate, the loss measured is \"binary cross-entropy\", and early stopping and reduce LR on plateau would be implemented (loss is monitored for early stopping) \n",
    "\n",
    "The model is as follows: (_Refer to model summary for more info_)\n",
    "  1. Fisrt Convolutional Block\n",
    "    * Input convolutional layer\n",
    "    * Batch normalization\n",
    "    * Max pooling layer\n",
    "  2. Second Convolutional Block\n",
    "    * Convolutional layer\n",
    "    * Convolutional layer\n",
    "    * Batch normalization \n",
    "    * Max pooling layer\n",
    "    * Dropout regularization\n",
    "  3. Third Convolutional Block\n",
    "    * Convolutional layer\n",
    "    * Convolutional layer\n",
    "    * Convolutional layer \n",
    "    * Max pooling layer\n",
    "  4. Flatten for dense network\n",
    "  5. First Dense Block\n",
    "    * Dense layer\n",
    "    * Dropout regularization\n",
    "  6. Second Dense Block\n",
    "    * Dense layer \n",
    "    * Dropout regularization\n",
    "  7. Output layer \n",
    "\n",
    "___ \n",
    "\n",
    "### 2.3 Compile Model & Prepare Callbacks\n",
    "\n",
    "Compile the model with the Adam optimizer, Binary Cross-Entropy loss and Accuracy as the measure of success\n",
    "\n",
    "The callback objects for early stopping, saving model checkpoints and reducing LR on plateau are prepared\n",
    "\n",
    "___\n",
    "\n",
    "### 2.4 Loading Previous Models\n",
    "\n",
    "Instead of fitting a model to the dataset from scratch, we can also load a model that was saved from a previous training and resume training from there\n",
    "\n",
    "This can be done either by loading from checkpoints (CKPT format) or a saved model (HDF5 format)\n",
    "\n",
    "If the whole model is loaded, there is no need to construct the whole model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juXNCJ0kpoWb"
   },
   "outputs": [],
   "source": [
    "# 2.1 \n",
    "# ImageDataGenerator is an iterator for data augmentation\n",
    "\n",
    "# As the images of the dataset are quite closely zoomed onto faces already, \n",
    "# the shift range is limited to only 0.1 to prevent the faces from going out of frame\n",
    "\n",
    "# The brightness is not altered too drastically as the model should ultimately be used in a well lit setting\n",
    "\n",
    "# Vertical flipping is not applied as we do not expect to see upside down faces in our use cases\n",
    "\n",
    "# Rescaling pixels to a value between 0.0 and 1.0 as a form of normalization \n",
    "# to increase training speeds, stability and comprehensiveness\n",
    "\n",
    "target_img_size = (224, 224)\n",
    "\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rotation_range=40, # Randomly rotates the image by up to 40 degrees\n",
    "    width_shift_range=0.1, # Displaces the image horizontally by up to 10% of the original image size\n",
    "    height_shift_range=0.1, # Displaces the image vertically by up to 10% of the original image size\n",
    "    brightness_range=[0.8, 1.2], # Alters brightness by a positive 20% or negative 20% \n",
    "    shear_range=0.3, # Shears by up to 30% in the counter-clockwise direction\n",
    "    zoom_range=0.2, # Randomly zooms in and out by up to 20%\n",
    "    horizontal_flip=True, # Randomly flips the image horizontally\n",
    "    rescale=1./255 # Rescales pixels to a float between 0 and 1\n",
    "    ) \n",
    "\n",
    "datagen_val = ImageDataGenerator(\n",
    "    rotation_range=40, # Same requirements repeated for validation dataset\n",
    "    width_shift_range=0.1, \n",
    "    height_shift_range=0.1, \n",
    "    brightness_range=[0.8, 1.2], \n",
    "    shear_range=0.3, \n",
    "    zoom_range=0.2, \n",
    "    horizontal_flip=True, \n",
    "    rescale=1./255\n",
    "    )\n",
    "\n",
    "datagen_test = ImageDataGenerator(\n",
    "    rescale=1./255 # No augmentation involved for testing dataset, just rescaling as the CNN is trained on normalized pixels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBXowuRXpuO9"
   },
   "outputs": [],
   "source": [
    "# 2.2\n",
    "# Best performing model discovered via experimentation so far, considering all limitations and conditions given\n",
    "# BPFModel\n",
    "\n",
    "# Initialize model\n",
    "model = Sequential()\n",
    "# First convol block\n",
    "model.add(Conv2D(32, (5, 5), strides=1, padding='same', activation='relu', kernel_regularizer=regularizers.L2(0.0001), input_shape=(224,224,3))) # input layer\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=2))\n",
    "# Second convol block\n",
    "model.add(Conv2D(64, (5, 5), strides=1, padding='valid', activation='relu', kernel_regularizer=regularizers.L2(0.0001)))\n",
    "model.add(Conv2D(64, (5, 5), strides=1, padding='same', activation='relu', kernel_regularizer=regularizers.L2(0.0001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=2))\n",
    "model.add(Dropout(0.4))\n",
    "# Third convol block\n",
    "model.add(Conv2D(128, (3, 3), strides=1, padding='same', activation='relu', kernel_regularizer=regularizers.L2(0.0001)))\n",
    "model.add(Conv2D(256, (3, 3), strides=1, padding='same', activation='relu', kernel_regularizer=regularizers.L2(0.0001)))\n",
    "model.add(Conv2D(64, (3, 3), strides=1, padding='same', activation='relu', kernel_regularizer=regularizers.L2(0.0001)))\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=2))\n",
    "# Flatten layer\n",
    "model.add(Flatten())\n",
    "# First dense block\n",
    "model.add(Dense(2000, kernel_regularizer=regularizers.L2(0.0001), activation='relu')) \n",
    "model.add(Dropout(0.4)) \n",
    "# Second dense block\n",
    "model.add(Dense(2000, kernel_regularizer=regularizers.L2(0.0001), activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "# Output block\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kv3fKypxp1Li",
    "outputId": "b203181d-1e05-4eaa-fad5-ff8c03acddb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 224, 224, 32)      2432      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 224, 224, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 107, 107, 64)      51264     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 107, 107, 64)      102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 107, 107, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 53, 53, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 53, 53, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 53, 53, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 53, 53, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 53, 53, 64)        147520    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2000)              86530000  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2000)              4002000   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 2001      \n",
      "=================================================================\n",
      "Total params: 91,207,089\n",
      "Trainable params: 91,206,897\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Double-checking the model \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2FVzcvzp30I"
   },
   "outputs": [],
   "source": [
    "# 2.3\n",
    "\n",
    "# Compiling the model\n",
    "opt = Adam(learning_rate=1e-4) # Using the adam optimizer which allows for adapting LRs, initialized as 0.0001\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy']) \n",
    "# Binary cross-entropy used as there are 2 categories predicted by one output neuron\n",
    "# Accuracy used as measure of success\n",
    "\n",
    "# Prepare for early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=1)\n",
    "\n",
    "# Prepare for model checkpoint saving\n",
    "checkpoint_path = \"/content/gdrive/<path to checkpoint storage>/<filename>.ckpt\" \n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# Prepare for reduced LR when approaching a plateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4\n",
    "# Load from a previously saved state of a trained model\n",
    "\n",
    "# Load previously saved weights from CKPT file\n",
    "model.load_weights(\"/content/gdrive/<path to CKPT file>/<filename>.ckpt\")\n",
    "\n",
    "# Load previously saved model from HDF5 file\n",
    "# model = load_model('/content/gdrive/<path to HDF5 file>/<filename>.h5')\n",
    "# If the whole model is loaded, there is no need to construct the whole model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaEX6xXgcsD4"
   },
   "source": [
    "# 3. Fitting the CNN Model\n",
    "\n",
    "___\n",
    "\n",
    "### 3.1 Prepare Dataset\n",
    "\n",
    "Prepare the training, validation and testing dataset using the flow_from_directory() method of the ImageDataGenerator object\n",
    "\n",
    "The method reads the images and yields them in batches from the corresponding folders using the filepath, batch size and target image size provided\n",
    "\n",
    "Shuffle is meant to introduce more randomness and the seed was set to 1 as a group decision in order to standardize within the group\n",
    "\n",
    "The images yielded may be altered according to the earlier set parameters at random\n",
    "\n",
    "Initially, the dataset was loaded using load_img() and img_to_array() and the augmentor iterates from memory using the flow() method. \n",
    "\n",
    "In order to standardize the dataset used however, flow_from_directory() method is now used instead to iterate from storage instead. \n",
    "\n",
    "___\n",
    "\n",
    "### 3.2 Fitting the CNN Model\n",
    "\n",
    "The model is fitted to the dataset, using the training and validation ImageDataGenerator and the 3 callback objects prepared\n",
    "\n",
    "The results are appended to a list called model_metadata\n",
    "\n",
    "___\n",
    "\n",
    "### 3.3 Load Previous Model\n",
    "\n",
    "Instead of fitting a new model to the dataset, we can also load a model that was saved from a previous training\n",
    "\n",
    "This can be done either by loading from checkpoints (CKPT format) or a saved model (HDF5 format)\n",
    "\n",
    "If the whole model is loaded, there is no need to construct the whole model from scratch\n",
    "\n",
    "___\n",
    "\n",
    "### 3.4 Evaluation\n",
    "\n",
    "The model's performance after fitting is then evaluated using the testing ImageDataGenerator\n",
    "\n",
    "A confusion matrix and classification report is also plotted to observe the model's other metrics of performance\n",
    "\n",
    "___\n",
    "\n",
    "### 3.5 Viewing the Predictions\n",
    "\n",
    "Using matplotlib.pyplot, we can see the image of predicted images alongside the prediction and true label\n",
    "\n",
    "___\n",
    "\n",
    "### 3.6 Saving Model\n",
    "\n",
    "The model can be saved in its entirety into an HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYWSq08OheNO",
    "outputId": "fe09fd05-4c34-429d-f831-da6bbd06b8d6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3561 images belonging to 2 classes.\n",
      "Found 1017 images belonging to 2 classes.\n",
      "Found 509 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 3.1\n",
    "\n",
    "# Standard batch size of 32 for time trade-off\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Paths to corresponding dataset folders\n",
    "train_path = \"/content/gdrive/<path to dataset storage>/data/train\" # Training dataset\n",
    "val_path = \"/content/gdrive/<path to dataset storage>/data/val\" # Validation datset\n",
    "test_path = \"/content/gdrive/<path to dataset storage>/data/test\" # Testing dataset\n",
    "\n",
    "# ImageDataGenerator can directly read the dataset from disk and create batches of images that are altered at random\n",
    "\n",
    "# Target image size is (224, 224), batch size is 32, class mode refers to the 2 classes predicted by the CNN model\n",
    "# Shuffle set to True indicates that the generator would select images to alter and yield randomly from a dataset that is random shuffled\n",
    "# Testing ImageDataGenerator has shuffle set to False so that the class labels used for the confusion matrix would be in the correct order\n",
    "\n",
    "train_gen = datagen_train.flow_from_directory(train_path, target_size=target_img_size, batch_size=BATCH_SIZE, class_mode=\"binary\", shuffle=True, seed=1)\n",
    "\n",
    "val_gen = datagen_val.flow_from_directory(val_path, target_size=target_img_size, batch_size=BATCH_SIZE, class_mode=\"binary\", shuffle=True, seed=1)\n",
    "\n",
    "test_gen = datagen_test.flow_from_directory(test_path, target_size=target_img_size, batch_size=BATCH_SIZE, class_mode=\"binary\", shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZaetFLi_qJlV",
    "outputId": "60a1033e-c0e8-4847-8f89-c1ed4a7b9965"
   },
   "outputs": [],
   "source": [
    "# 3.2\n",
    "# Preparing the list to store details of the model's training performance\n",
    "model_metadata = []\n",
    "\n",
    "# Fitting the model\n",
    "model_metadata.append(\n",
    "    model.fit_generator(train_gen, \n",
    "              steps_per_epoch=ceil(3561/BATCH_SIZE),\n",
    "              epochs=15, \n",
    "              callbacks=[early_stopping, reduce_lr, model_checkpoint],\n",
    "              validation_data=val_gen,\n",
    "              validation_steps=ceil(1017/BATCH_SIZE),\n",
    "              verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3\n",
    "# Load from a previously saved state of a trained model\n",
    "\n",
    "# Load previously saved weights from CKPT file\n",
    "model.load_weights(\"/content/gdrive/<path to CKPT file>/<filename>.ckpt\")\n",
    "\n",
    "# Load previously saved model from HDF5 file\n",
    "# model = load_model('/content/gdrive/<path to HDF5 file>/<filename>.h5')\n",
    "# If the whole model is loaded, there is no need to construct the whole model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C9v0P-k06E5J",
    "outputId": "39aee1d4-652f-48c3-ae02-b5a3ceee73b1"
   },
   "outputs": [],
   "source": [
    "# 3.4\n",
    "# Observing the results\n",
    "\n",
    "# Use evaluate() method to evaluate performance metrics of accuracy and loss\n",
    "model_metadata.append(\n",
    "    model.evaluate(test_gen, verbose=1, return_dict=True)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ie-SlV8IeiLO",
    "outputId": "be1cf897-9204-4ed3-c21a-e485170e9f3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9410609006881714, 'loss': 0.6789568066596985}"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe the returned results of the evaluate() method\n",
    "model_metadata[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "tCLQAbj19ZeC",
    "outputId": "1940ef1e-7e8b-473e-9ba3-93e4afc5aaa3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f85e5a01d68>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD4CAYAAADSIzzWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAV6klEQVR4nO3deXwV9bnH8c9DsFVANpGdigsucGtxqWJdqi8XRG5BWoqABaRq0GIL1g1BcQNXcKdIVFSogKhYARdE9Kq4IVqvCtYrIggRkrCIKCgkee4fGfAAWU6Sk/xyhu+b1++VOb+ZM/Mbzevh4ZnfzJi7IyIi1a9W6AGIiOyuFIBFRAJRABYRCUQBWEQkEAVgEZFAalf1AbYsXaBpFrKLOof2CD0EqYHyt2RbZfexdc3SpGPOHk0OqPTxKkMZsIhIIFWeAYuIVKvCgtAjSJoCsIjES0F+6BEkTQFYRGLFvTD0EJKmACwi8VKoACwiEoYyYBGRQHQRTkQkEGXAIiJhuGZBiIgEootwIiKBqAQhIhKILsKJiASiDFhEJBBdhBMRCUQX4UREwnBXDVhEJAzVgEVEAlEJQkQkEGXAIiKBFGwNPYKk6Z1wIhIvhYXJt1KYWRsze9XMFpvZIjMbEvVfb2bZZvZh1M5K+M7VZrbEzD4zs85lDVUZsIjES+pKEPnAZe7+gZntDbxvZnOjdXe5+5jEjc2sPdAb6AC0BF42s4O9lGkZCsAiEi8pugjn7quAVdHyRjP7FGhVyle6A9Pc/UfgSzNbAhwDvF3SF1SCEJF4SVEJIpGZtQWOAN6Nui4xs4/MbKKZNYr6WgErEr62ktIDtgKwiMSLF2xNuplZppktTGiZO+/PzOoBTwND3f1bYDxwINCRogx5bEXHqhKEiMRLOWrA7p4FZJW03sz2oCj4Pu7uM6Lv5CSsfxCYHX3MBtokfL111FciZcAiEi+pmwVhwMPAp+5+Z0J/i4TNegCfRMszgd5m9nMz2x9oBywo7RjKgEUkXlI3C+J4oB/wsZl9GPUNB/qYWUfAgWXAIAB3X2Rm04HFFM2gGFzaDAhQABaRuEndLIj5gBWz6vlSvjMaGJ3sMRSARSRedCuyiEgg+Xogu4hIGMqARUQC0eMoRUQCUQYsIhKIMmARkUCUAYuIBKJZECIigbiHHkHSFIBFJF5UAxYRCUQBWEQkEF2EExEJpKDUB5DVKArAIhIvKkGIiASiACwiEohqwCIiYXih5gGLiIShEoSISCCaBSEiEogyYBGRQBSA09/qvLUMHzOBtes3YGb07HIKfzq78w7bPPLUczz36lsAFBQUsHTF17w+7R802LtehY+7ZctWho+dwOLPv6Rh/XrccfUltGq2L2998DF3PzKdrfn57FG7Nped35tjO3ao1DlK9XswayxdzzqN3Lw1dDziVAAaNWrI1MfHs99+bVi+fAW9+17EN99sCDzSNJZGD+OpFXoANVVGRgaXX9iXZ7Nu4/G7rmPa7Jf5Ynn2DtsM7NmVp8aN5qlxoxlyXi+O/uWhSQff7Jw8Bl6569urZ7z0GvXr1eX5iWPpd/aZ3DXxCQAa1d+b+6//O8+Mv4XRl2UyfMyEyp+kVLtJk6bT9b/P3aHvqisH88qr8zmswwm88up8rrpycKDRxURhYfItsDIDsJkdamZXmdm9UbvKzA6rjsGFtG/jhrQ/qC0Adevsxf5tWpKzdl2J2z//2jt0+e1x2z/PeuVN+gy5jp6DR3DDvRMpKEjuf/arb39At9NOAOD0E4/h3Q8X4e4cdlBbmu7TCICD9mvNDz9uYcuWrRU8Ownljfnvsm79Nzv0/e53nZk0+UkAJk1+km7dzgwxtPgo9ORbYKUGYDO7CpgGGLAgagZMNbNhVT+8miE7J4//fLGcww85qNj1m3/4kTcXfsTpJ/wagKVfZTPntXeYNPZanho3moxatbaXKsqSu3YdzZvsA0DtjAzq1anDN99+t8M2c+e/x2EHteVnP9ujEmclNUWzpk1YvToXgNWrc2nWtEngEaW5goLkW2Bl1YDPBzq4+w6plpndCSwCbi3uS2aWCWQCjBs1jAv69EjBUMPYtPkHLh11L1cNOpd6dfcqdpvX3v03R7Rvt7388M6Hi1m8ZBl9hlwHwI8/bqFxw/oADLnxbrJz8ti6NZ9VeWvpOXgEAOd270yPM04qczxLlq/krolPkDX6ylScntRAnkY1zJrIa0BpIVllBeBCoCWwfKf+FtG6Yrl7FpAFsGXpgrT9bdqan8+lo+6l6ym/4bTjf13idi+89g5dTv6p/ODudDvtBIYOPGeXbe8ZORQoyqqvGZvFI7eP2GF9030as3rNWprv25j8ggK+27SJhvWLAvvqvHUMvekebr58EG1aNkvFKUoNkJO7hubNm7J6dS7NmzclN29t6CGltxpQWkhWWTXgocA8M3vBzLKi9iIwDxhS9cMLx9257u6HOKBNSwb8vkuJ2238fhMLP/4Ppxx35Pa+Th07MHf+e6yNrmRv2PgdX+esSeq4J3c6gpkvzwdg7hsLOOZX7TEzvv3uewZfN4ahA3txRIeDK3FmUtPMnvUS/fv9EYD+/f7IrFlzAo8ozXlh8i2wUjNgd3/RzA4GjgFaRd3ZwHvuHr6AUoX+vej/mDXvTdq1bbO9TPC3AX9kdZSd9OpaNIVo3lsL+c2R/0WdPffc/t0D92vFX/v3ZNCI2yksdGrXzmDEXwbQslnZtb3fd/4tV9/xAGf9+TIa7F2P24cVXRGfOmsuK77O4YEp/+KBKf8CYMLoK9mnYYOUnrdUrX9OHsdvTzqOJk0as2zpQm64cQy33TGOaVMeYOB5ffjqq5X07ntR6GGmtzTKgK2q603pXIKQqlPn0PS9LiBVJ39LtlV2H9+P7J10zKl747RKH68ydCOGiMRLDSgtJEsBWETiJY1KELoTTkRixQsLk26lMbM2ZvaqmS02s0VmNiTqb2xmc83s8+hno6jfopvVlpjZR2Z2ZKkHQAFYROImdXfC5QOXuXt7oBMw2MzaA8OAee7ejqIZYdtuSusCtItaJjC+rAMoAItIvKQoALv7Knf/IFreCHxK0Wyw7sBj0WaPAWdHy92BSV7kHaChmbUo7RgKwCISL+W4FdnMMs1sYULLLG6XZtYWOAJ4F2jm7quiVauBbXdFtQJWJHxtJT9N3y2WLsKJSKyU551wiXftlsTM6gFPA0Pd/Vuzn2auububWYWv+ikAi0i8pHAWhJntQVHwfdzdZ0TdOWbWwt1XRSWG3Kg/G2iT8PXWUV+JVIIQkXhJ0fOArSjVfRj41N3vTFg1ExgQLQ8Ank3o7x/NhugEbEgoVRRLGbCIxEvqMuDjgX7Ax2b2YdQ3nKKnQE43s/MpelBZr2jd88BZwBJgEzCwrAMoAItIvKQoALv7fIqef16cU4vZ3oFyvc5EAVhEYsWTfPtMTaAALCLxkka3IisAi0islGcaWmgKwCISLwrAIiKBpE8JWAFYROLF89MnAisAi0i8pE/8VQAWkXjRRTgRkVCUAYuIhKEMWEQkFGXAIiJheH7oESRPAVhEYiWN3kqvACwiMaMALCIShjJgEZFAFIBFRALxgpKeoV7zKACLSKwoAxYRCcQLlQGLiAShDFhEJBB3ZcAiIkEoAxYRCaRQsyBERMLQRTgRkUAUgEVEAvH0eRywArCIxIsyYBGRQDQNTUQkkALNghARCUMZsIhIIOlUA64VegAiIqnknnwri5lNNLNcM/skoe96M8s2sw+jdlbCuqvNbImZfWZmncvavzJgEYmVFGfAjwL3A5N26r/L3cckdphZe6A30AFoCbxsZge7e0FJO1cGLCKxUlBYK+lWFnd/HViX5KG7A9Pc/Ud3/xJYAhxT2hcUgEUkVspTgjCzTDNbmNAykzzMJWb2UVSiaBT1tQJWJGyzMuorkQKwiMRKoVvSzd2z3P3ohJaVxCHGAwcCHYFVwNiKjlU1YBGJlaqehubuOduWzexBYHb0MRtok7Bp66ivRMqARSRWUjkLojhm1iLhYw9g2wyJmUBvM/u5me0PtAMWlLavKs+A67fvWdWHkDS0+es3Qg9BYqowhRmwmU0FTgaamNlK4DrgZDPrCDiwDBgE4O6LzGw6sBjIBwaXNgMCVIIQkZhJZnZDsty9TzHdD5ey/WhgdLL7VwAWkVhJo6dRKgCLSLyksgRR1RSARSRW9DAeEZFA0uilyArAIhIvjjJgEZEg8lWCEBEJQxmwiEggqgGLiASiDFhEJBBlwCIigRQoAxYRCSON3smpACwi8VKoDFhEJAw9jEdEJBBdhBMRCaTQVIIQEQmi1FdQ1DAKwCISK5oFISISiGZBiIgEolkQIiKBqAQhIhKIpqGJiARSoAxYRCQMZcAiIoEoAIuIBJJGr4RTABaReFEGLCISiG5FFhEJRPOARUQCUQlCRCSQdArAtUIPQEQklbwcrSxmNtHMcs3sk4S+xmY218w+j342ivrNzO41syVm9pGZHVnW/hWARSRWCi35loRHgTN36hsGzHP3dsC86DNAF6Bd1DKB8WXtXAFYRGKloBytLO7+OrBup+7uwGPR8mPA2Qn9k7zIO0BDM2tR2v4VgEUkVgrxpJuZZZrZwoSWmcQhmrn7qmh5NdAsWm4FrEjYbmXUVyJdhBORWCnPRTh3zwKyKnosd3czq/AjiJUBi0ispPIiXAlytpUWop+5UX820CZhu9ZRX4kUgEUkVgrL0SpoJjAgWh4APJvQ3z+aDdEJ2JBQqiiWShAiEiv5Fa8I7MLMpgInA03MbCVwHXArMN3MzgeWA72izZ8HzgKWAJuAgWXtXwFYRGIlle+Ec/c+Jaw6tZhtHRhcnv0rAItIrKTTnXAKwCISK4Vp9F5kBWARiZX0Cb8KwCISMypBiIgEUpBGObACsIjEijJgEZFAXBmwiEgYyoCFCRPuoEuXU8nLW8tRR50OwDXXXMrAgX1Ys2YtACNH3s6cOa+GHKaU06qcPIbfNIa169djGD27d6Ffr7N32Gbjd98z7MbbWZWTR0F+Aef1/QM9up5RqeNu+HYjl117C1+vzqFl82aMvelqGtTfm9lzXuHhx58Ehzp19uLayy/h0HYHVOpY6S6dpqHpWRBVZPLkJ+nWrf8u/ffd9xDHHtuFY4/touCbhmpnZHDFXy9k5uNZTMm6i2kzZvPFl8t32Gbq07M4sO0vmPHYP3jk/tu4474H2bp1a1L7X/DBR4wYNXaX/ocmT6fT0R15/omH6XR0Rx7+53QAWrVszqP3384zk8dz0Xl9uOH2eyt/kmmuGh7GkzIKwFVk/vwFrF//TehhSIrt26Qx7Q85CIC6detwwH5tyMlbu8M2Zsb3mzbj7mza/AMN6u9NRkYGABMff4pzzv8bPfpfzP0PTU76uK++8Tbdu5wGQPcup/HK628DcMQv29Og/t4AHN7hUHJy11T6HNNdPp50C00BuJpdfPEA3ntvDhMm3EHDhg1CD0cqIXtVDp9+/gWHdzhkh/6+f/gdS5et4JTu59Kj/8UMG3oRtWrV4s133+erldlMe+genn50HIs/W8LCDz9O6lhr13/Dvk0aA9Bkn0asLeYv9xmz53BCp6Mrf2JpzsvxJ7QK14DNbKC7P1LCukyK3olE7dqNyMioV9HDxEpW1mRuvvke3J3rr7+c2267hkGDrgg9LKmATZs2c+mIUVz1t0HUq1t3h3VvLnifQ9sdwMT7bmVF9iouHDqco37Vgbfe+4C3FnxAz/MuKdrH5s0sX/E1R3f8JX0uHMqWLVvZtHkzG77dyB8GFD3T5e9/+TPHH3vUDvs3M8x2fKHZgvf/lxmzX2Ly+DFVeNbpYXe5CHcDUGwATnzK/J57/iL8XzM1RG7CPw8nTpzKjBnF/ueTGm5rfj5DR4yi6xmncPrJx++y/pnn5nLBn3phZvyidUtatWjOl8tXgsMF/c6h19ln7fKdqQ/eDRTVgJ99fi6jr7lsh/X7NGpI3pp17NukMXlr1tE44V9Pny35kpG33s0DY2+iYYP6KT7b9FMTMttklVqCiF6tXFz7mJ/egyRJat686fblbt06s2jRZwFHIxXh7oy85W4O2K8NA3r/vthtWjTbl3fe/xCANevWs+yrlbRu2ZzfHHMkzzz3Eps2bQYgJ29NsaWE4px8QieefeFlAJ594WVOOfE4AFatzmXo8Ju4ZeQVtP1F68qeXixUwwPZU6asDLgZ0BlYv1O/AW9VyYhiYtKk+zjxxONo0qQRS5a8y6hRd3LSScdx+OHtcXeWL1/JJZdcHXqYUk7//mgRs16cR7sD224vEwwZNIBVOXkAnNOjKxed15cRo8fSo9/FuDuX/uXPNGrYgOOPPYqly1dw7qC/A1Bnrz25ZeQV7NOoYZnHvaBfLy679mZmzJ5Dy+ZNGXvTcADGPzKFDd9uZNSYcQBkZGQwfeLuPROiwNMnAzYvZbBm9jDwiLvPL2bdFHfvW9YBVIKQ4mxc+T+hhyA10B5NDrCytypd3/16JB1zpix/ptLHq4xSM2B3P7+UdWUGXxGR6pZONWDdCScisVITarvJUgAWkVhJp1uRFYBFJFZUghARCSSdZkEoAItIrKgEISISiC7CiYgEohqwiEggKkGIiARS2t29NY0CsIjEil5LLyISiEoQIiKBqAQhIhKIMmARkUBSOQ3NzJYBG4ECIN/djzazxsATQFtgGdDL3Xd+ZnpS9FJOEYmVAvekW5JOcfeO7r7tjafDgHnu3g6YF32uEAVgEYmVQjzpVkHdgcei5ceAsyu6IwVgEYmVFAdgB14ys/ejt70DNHP3VdHyairxfkzVgEUkVsozCyIKqpkJXVnRW923OcHds82sKTDXzP6z07HczCqcSisAi0islKe0EAXbrFLWZ0c/c83sGeAYIMfMWrj7KjNrAeRWdKwqQYhIrHg5/pTGzOqa2d7bloEzgE+AmcCAaLMBwLMVHasyYBGJlQJP2QMpmwHPmBkUxcop7v6imb0HTDez84HlQK+KHkABWERiJVV3wrn7UuBXxfSvBU5NxTEUgEUkVnQnnIhIIHogu4hIIIV6GI+ISBjKgEVEAknhLIgqpwAsIrGiEoSISCAqQYiIBKIMWEQkEGXAIiKBFHhB6CEkTQFYRGJFL+UUEQlEtyKLiASiDFhEJBDNghARCUSzIEREAtGtyCIigagGLCISiGrAIiKBKAMWEQlE84BFRAJRBiwiEohmQYiIBKKLcCIigagEISISiO6EExEJRBmwiEgg6VQDtnT62yLdmVmmu2eFHofULPq92H3VCj2A3Uxm6AFIjaTfi92UArCISCAKwCIigSgAVy/V+aQ4+r3YTekinIhIIMqARUQCUQAWEQlEAbiamNmZZvaZmS0xs2GhxyPhmdlEM8s1s09Cj0XCUACuBmaWAYwDugDtgT5m1j7sqKQGeBQ4M/QgJBwF4OpxDLDE3Ze6+xZgGtA98JgkMHd/HVgXehwSjgJw9WgFrEj4vDLqE5HdmAKwiEggCsDVIxtok/C5ddQnIrsxBeDq8R7Qzsz2N7OfAb2BmYHHJCKBKQBXA3fPBy4B5gCfAtPdfVHYUUloZjYVeBs4xMxWmtn5occk1Uu3IouIBKIMWEQkEAVgEZFAFIBFRAJRABYRCUQBWEQkEAVgEZFAFIBFRAL5fwNXZD+SG0zvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the confusion matrix \n",
    "\n",
    "# Getting the predictions\n",
    "y_pred = model.predict(test_gen, verbose=1)\n",
    "y_pred = (y_pred > 0.5).astype('int32')\n",
    "\n",
    "# Getting the class labels\n",
    "y_classes = list(test_gen.class_indices)\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "cm = confusion_matrix(test_gen.classes, y_pred)\n",
    "sns.heatmap(cm, annot=True, xticklabels=y_classes, yticklabels=y_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7hw91SGP6j7y",
    "outputId": "1fb891a7-4cff-4b8e-b008-883f80bb529e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9565217391304348\n",
      "0.9491525423728814\n",
      "0.9655172413793104\n",
      "0.9572649572649573\n"
     ]
    }
   ],
   "source": [
    "# Scores according to different metrics\n",
    "\n",
    "# Accuracy \n",
    "print(\"Accuracy: \", end=\"\")\n",
    "print(accuracy_score(test_gen.classes, y_pred))\n",
    "\n",
    "# Recall\n",
    "print(\"Recall: \", end=\"\")\n",
    "print(recall_score(test_gen.classes, y_pred))\n",
    "\n",
    "# Precision \n",
    "print(\"Precision: \", end=\"\")\n",
    "print(precision_score(test_gen.classes, y_pred))\n",
    "\n",
    "# F1\n",
    "print(\"F1 score: \", end=\"\")\n",
    "print(f1_score(test_gen.classes, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xWtU0446jYc"
   },
   "outputs": [],
   "source": [
    "# Creating the classification report\n",
    "\n",
    "print(classification_report(test_gen.classes, y_pred, target_names=y_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 \n",
    "# Viewing the image and corresponding class and prediction by the model\n",
    "\n",
    "# Getting a batch of images \n",
    "batch = test_gen.__next__()\n",
    "\n",
    "# Getting predictions on that batch\n",
    "results = model.predict(batch, verbose=1)\n",
    "results = (results > 0.5).astype('int32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picture to be reviewed\n",
    "image = 1\n",
    "\n",
    "# Get the true class\n",
    "print(f\"Correct Class: {batch[1][image]}\")\n",
    "\n",
    "# Get the predicted class\n",
    "print(f\"Predicted Class: {results[image]}\")\n",
    "\n",
    "# Get the image \n",
    "plt.imshow(batch[0][image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.6\n",
    "# Saving the model in HDF5 format\n",
    "\n",
    "model.save('/content/gdrive/<path to location to save file to>/<filename>.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "L2T5c_7FogQJ"
   ],
   "name": "KW Own Architecture.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
