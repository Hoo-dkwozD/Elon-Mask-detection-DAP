{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeD0mfeY-EMo"
   },
   "source": [
    "# Code Stack for Back-End / Webcam integration\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. Forming a 'hypermodel' comprising our best models using ensemble methods\n",
    "\n",
    "2. Integration with live video streaming using OpenCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PnPSacIpAKVG"
   },
   "outputs": [],
   "source": [
    "# Import needed modules\n",
    "\n",
    "# Basic packages needed for data analysis, visualization and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Mainly Tensorflow packages for data preprocessing\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    "# Mainly Tensorflow.keras layers and pre-trained Convolutional Neural Network (CNN) models needed to do Transfer Learning\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten, BatchNormalization, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras import Sequential, regularizers, Model\n",
    "\n",
    "# Mainly Tensorflow modules that help to optimize and fine-tune the CNN models better\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from sklearn.model_selection import KFold, train_test_split \n",
    "from math import ceil\n",
    "\n",
    "# Mainly metrics to assess the CNN's performance\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score\n",
    "\n",
    "# Mainly packages for webcam integration\n",
    "import re\n",
    "import cv2\n",
    "import imutils\n",
    "from imutils.video import VideoStream\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbZeevbN_eQW"
   },
   "source": [
    "## 1. Using ensemble methods on best models\n",
    "\n",
    "We'll gather the best models and form a soft voting classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eb0rUivM_zrj"
   },
   "source": [
    "#### 1.1 Function for model generation\n",
    "\n",
    "Each model to be included in the 'Hypermodel' has its own constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vKGRSPtA9wq9"
   },
   "outputs": [],
   "source": [
    "# 1.1\n",
    "# Returns the model and the output layer's activation function\n",
    "# Different models by the team use different output formats\n",
    "\n",
    "def model_1():\n",
    "  \"Returns __'s CNN model and its activation function as inferred by the crossentropy used ('Binary', 'Categorical')\"\n",
    "\n",
    "  model = <code for constructing model>\n",
    "  # Model's code using Keras\n",
    "\n",
    "  output_activation = <type of crossentropy used>\n",
    "  \n",
    "  return (model, output_activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7nywYRABwWh"
   },
   "source": [
    "#### 1.2 Class for 'Hypermodel'\n",
    "\n",
    "The Class for the 'hypermodel' to be generated in the following function\n",
    "\n",
    "Documentation for the `Hypermodel` class\n",
    "___\n",
    "\n",
    "### Hypermodel\n",
    "\n",
    "`Hypermodel` is an ensemble model encompassing the best models the team have so far, using a soft, average voting classifier\n",
    "\n",
    "```python\n",
    "Hypermodel(\n",
    "    name=None\n",
    ")\n",
    "```\n",
    "\n",
    "#### Examples:\n",
    "\n",
    "```python\n",
    "model_1 = model_1() # Following the functions mentioned earlier, is a tuple\n",
    "model_2 = model_2() # Following the functions mentioned earlier, is a tuple\n",
    "\n",
    "ensemble_model = Hypermodel(\"test\") # Instantiate `Hypermodel`\n",
    "\n",
    "# Add models\n",
    "ensemble_model.add_tuple(model_1) \n",
    "ensemble_model.add_tuple(model_2)\n",
    "\n",
    "# Prepare Iterator\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "X = datagen.flow_from_directory(\"<path>\", target_size=(224, 224), batch_size=32, class_mode='binary')\n",
    "\n",
    "# Predict\n",
    "results = ensemble_model.predict(X)\n",
    "```\n",
    "\n",
    "#### Arguments: \n",
    "\n",
    "| Parameter | Description |\n",
    "| :--- | :--- |\n",
    "| __Name__ | Optional name for the Hypermodel |\n",
    "\n",
    "#### Attributes:\n",
    "\n",
    "| Attribute | Description |\n",
    "| :--- | :--- |\n",
    "| **collections** | A list containing all the models we want to include |\n",
    "| **mo_collections** | A list containing match objects for the maintenance of Hypermodel's string representation |\n",
    "| **model_types** | A list containing the output type of the models in the `collections` attribute |\n",
    "| **name** | The name given to the Hypermodel | \n",
    "| **no_of_models** | The number of models included so far |\n",
    "| **removal_match** | The Regular Expression object used for maintenance of Hypermodel's string representation |\n",
    "| **str_rep** | An essential part in Hypermodel's string representation |\n",
    "\n",
    "#### Methods: \n",
    "\n",
    "___\n",
    "\n",
    "__*add*__\n",
    "\n",
    "```python\n",
    "add(\n",
    "    *models\n",
    ")\n",
    "```\n",
    "\n",
    "Adds model instances produced by model generation functions mentioned earlier to the `Hypermodel`\n",
    "\n",
    "__Arguments:__\n",
    "\n",
    "| Parameter | Description |\n",
    "| :--- | :--- |\n",
    "| __\\*models__ | Any number of model instances |\n",
    "\n",
    "___\n",
    "\n",
    "**_add_tuple_**\n",
    "\n",
    "```python\n",
    "add_tuple(\n",
    "    *args\n",
    ")\n",
    "```\n",
    "\n",
    "Adds model instances and its corresponding model output type generated by the model generation functions mentioned earlier to the `Hypermodel`\n",
    "\n",
    "__Arguments:__\n",
    "\n",
    "| Parameter | Description |\n",
    "| :--- | :--- |\n",
    "| __\\*args__ | Any number of tuples containing the `(<model instance>, <model output type>)` |\n",
    "\n",
    "__Raises:__\n",
    "\n",
    "| Error | Reason |\n",
    "| :--- | :--- |\n",
    "| __TypeError__ | If the individual elements of `*args` are not tuples |\n",
    "\n",
    "___\n",
    "\n",
    "**_drop_**\n",
    "\n",
    "```python\n",
    "drop(\n",
    "    ind=None\n",
    ")\n",
    "```\n",
    "\n",
    "Removes either the most recently added model instance and its corresponding model output type or the model instance and corresponding output type specified by the `ind` parameter as the index in the `collections` and `model_types` attributes\n",
    "\n",
    "__Arguments:__\n",
    "\n",
    "| Parameter | Description |\n",
    "| :--- | :--- |\n",
    "| __ind__ | If `ind` is `None`, the latest model instance and type is removed. If `ind` is a specified integer, the model instance and output type at the index position `ind` specifies would be removed |\n",
    "\n",
    "__Raises:__\n",
    "\n",
    "| Error | Reason |\n",
    "| :--- | :--- |\n",
    "| __OutOfBoundError__ | If the number specified by `ind` is out of range |\n",
    "\n",
    "___\n",
    "\n",
    "**_name_**\n",
    "\n",
    "```python\n",
    "name(\n",
    "    name\n",
    ")\n",
    "```\n",
    "\n",
    "Names or renames the `Hypermodel`\n",
    "\n",
    "__Arguments:__\n",
    "\n",
    "| Parameter | Description |\n",
    "| :--- | :--- |\n",
    "| __name__ | Name for the `Hypermodel`, which automatically be converted into a string if it isn't one |\n",
    "\n",
    "___\n",
    "\n",
    "**_predict_**\n",
    "\n",
    "```python\n",
    "predict(\n",
    "    X,\n",
    "    steps=None,\n",
    "    verbose=0,\n",
    "    print_out=False\n",
    ")\n",
    "```\n",
    "\n",
    "Predicts the result of the dataset specified via `X` parameter in a similar way to Keras's Sequential object predict() method  \n",
    "Gathers and averages out the predictions for all the models included\n",
    "\n",
    "__Arguments:__\n",
    "\n",
    "| Parameter | Description |\n",
    "| :--- | :--- |\n",
    "| __X__ | Either an Iterator yielding `numpy` arrays or a collection of `numpy` arrays which are the images to feed to the models |\n",
    "| __steps__ | Only used when `X` is an iterator to indicate the number of batches to predict over and should be left as `None` if a collection is used in `X`. If `X` is an iterator but `steps` is left as `None`, an exhaustive number of batches would be used as derived from the iterator |\n",
    "| __verbose__ | If set to `0`, it only returns the Boolean values of each prediction. For any other number, both the Boolean and real floating point values are included |\n",
    "| **print_out** | If set to `True`, the results would be printed out, otherwise, it defaults to `False` and only returns but does not print the results to `stdout` |\n",
    "\n",
    "__Raises:__ \n",
    "\n",
    "| Error | Reason |\n",
    "| :--- | :--- |\n",
    "| __ArgumentError__ | If `X` is a collection but `steps` is not `None` |\n",
    "| __TypeError__ | If `X` is neither a collection (`np.array`, `list`, `tuple`) or iterator (`Iterator`, `DirectoryIterator`) |\n",
    "\n",
    "__Returns:__\n",
    "\n",
    "| Variable | Description |\n",
    "| :--- | :--- |\n",
    "| __results__ | A `np.array` of the predictions |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXpu7DaxCEID"
   },
   "outputs": [],
   "source": [
    "# 1.2\n",
    "# Class for 'hypermodel'\n",
    "\n",
    "class Hypermodel:\n",
    "  \"Hypermodel acts as an ensemble classifier for different CNN models\"\n",
    "\n",
    "  def __init__(self, name = None):\n",
    "    self.collections = []\n",
    "    self.mo_collections = [] # 'mo' stands for match object from the 're' library\n",
    "    self.model_types = []\n",
    "    if name is None: \n",
    "      self.name = name\n",
    "    else:\n",
    "      self.name = str(name)\n",
    "    self.no_of_models = 0\n",
    "    self.removal_match = re.compile('\\n\\n\\t>>> Model.*[0-9]+.*<')\n",
    "    self.str_rep = f\"Hypermodel[{self.no_of_models}]: \"\n",
    "  \n",
    "  def __str__(self): \n",
    "    if self.name is None: \n",
    "      return \"|==>>> \" + self.str_rep + \"\\n\\n\\t|^^^^^\"\n",
    "    else: \n",
    "      return \"|==>>> \" + self.name + \" \" + self.str_rep + \"\\n\\n\\t|^^^^^\"\n",
    "  \n",
    "  def __repr__(self): \n",
    "    if self.name is None: \n",
    "      return \"|==>>> \" + self.str_rep + \"\\n\\n\\t|^^^^^\"\n",
    "    else: \n",
    "      return \"|==>>> \" + self.name + \" \" + self.str_rep + \"\\n\\n\\t|^^^^^\"\n",
    "  \n",
    "  def name(self, name):\n",
    "    \"Names the Hypermodel\"\n",
    "    self.name = str(name)\n",
    "  \n",
    "  def _update(self, past_no):\n",
    "    \"Helper function to update string representation\"\n",
    "    self.str_rep = self.str_rep[:11] + str(self.no_of_models) + self.str_rep[11 + past_no:]\n",
    "    # Adjusts the first part of the str representation that states the number of models included currently\n",
    "    # 11 is because the number of char there are till '[' in \"Hypermodel[<no_of_models>]...\" is 11\n",
    "    temp_iter = self.removal_match.finditer(self.str_rep)\n",
    "    self.mo_collections = [] # The collection of match objects is recompiled every _update call\n",
    "    for _ in range(self.no_of_models):\n",
    "      self.mo_collections.append(temp_iter.__next__()) # The purpose of storing match objects is for the drop method\n",
    "\n",
    "  def add(self, *models):\n",
    "    \"Adds model instances into Hypermodel\"\n",
    "    temp = len(str(self.no_of_models)) # Keep track of the number of char the old number of models had for _update()\n",
    "    for model in models:\n",
    "      self.collections.append(model)\n",
    "      self.model_types.append(None) # Unknown model output type\n",
    "      self.no_of_models += 1\n",
    "      self.str_rep += \"\\n\\n\\t>>> Model (\" + str(self.no_of_models) + \") <\"\n",
    "    \n",
    "    self._update(temp) # Update str representation\n",
    "\n",
    "  def add_tuple(self, *args): \n",
    "    \"Adds model instances and output type into Hypermodel\"\n",
    "    temp = len(str(self.no_of_models)) # Keep track of the number of char the old number of models had for _update()\n",
    "    for arg in args:\n",
    "      try: \n",
    "        assert isinstance(arg, tuple)\n",
    "      except:\n",
    "        raise TypeError\n",
    "      self.collections.append(arg[0])\n",
    "      self.model_types.append(arg[1])\n",
    "      self.no_of_models += 1\n",
    "      self.str_rep += \"\\n\\n\\t>>> Model (\" + str(self.no_of_models) + \") <== \" + str(arg[1]) + \" <\"\n",
    "    \n",
    "    self._update(temp) # Update str representation\n",
    "    \n",
    "  def drop(self, ind=None):\n",
    "    \"Removes model instance from Hypermodel\"\n",
    "    temp = len(str(self.no_of_models)) # Keep track of the number of char the old number of models had for _update()\n",
    "    if self.no_of_models != 0 and ind is None: # Remove latest model instance\n",
    "      self.collections.pop()\n",
    "      self.model_types.pop()\n",
    "      self.no_of_models -= 1\n",
    "      self.str_rep = self.str_rep[:self.mo_collections[-1].start()] + self.str_rep[self.mo_collections[-1].end():]\n",
    "      # Edit str representation using the match objects collection\n",
    "    elif self.no_of_models != 0 and ind < self.no_of_models and ind is not None: # Remove specified model instance\n",
    "      self.collections.pop(ind)\n",
    "      self.model_types.pop(ind) \n",
    "      self.no_of_models -= 1\n",
    "      self.str_rep = self.str_rep[:self.mo_collections[ind-1].start()] + self.str_rep[self.mo_collections[ind-1].end():]\n",
    "      # Edit str representation using the match objects collection\n",
    "    else:\n",
    "      raise OutOfBoundError\n",
    "    \n",
    "    self._update(temp) # Update str representation\n",
    "  \n",
    "  def _output_interface(self, result):\n",
    "    \"\"\"\n",
    "    Helper function acting as an interface to simplify handling of prediction results by different models\n",
    "    with different output types\n",
    "    \"\"\"\n",
    "    if len(result[0]) == 1: # Binary crossentropy/Sigmoid function used\n",
    "      if len(result) == 1: # One image only\n",
    "        return result[0][0]\n",
    "      else: # Batch procesing\n",
    "        temp = []\n",
    "        for i in result:\n",
    "          temp.append(i[0])\n",
    "        return temp\n",
    "    elif len(result[0]) == 2: # Categorical crossentropy/Softmax function used\n",
    "      choice = 0 # The output neuron position/one-hot encoding position for the target class\n",
    "      if len(result) == 1: # One image only\n",
    "        return result[0][choice]\n",
    "      else: # Batch procesing\n",
    "        temp = []\n",
    "        for j in result:\n",
    "          temp.append(j[choice])\n",
    "        return temp\n",
    "\n",
    "  def predict(self, X, steps=None, verbose=0, print_out=False): \n",
    "    \"Predicts the result based on the image inputs using a soft-voting, averaging ensemble method\"\n",
    "    results = np.array([])\n",
    "    if isinstance(X, np.ndarray) or isinstance(X, list) or isinstance(X, tuple): # For collections\n",
    "      if steps is not None:\n",
    "        raise ArgumentError # Steps should be None\n",
    "      for x in X: # Iterate through every image\n",
    "        temp_result = 0 \n",
    "        temp_test = np.asarray([x])\n",
    "        for model in self.collections: # Gather each model's vote\n",
    "          temp_result += self._output_interface(model.predict(temp_test))\n",
    "        temp_bool = (temp_result/self.no_of_models) > 0.5 # Average out the votes\n",
    "        if bool(verbose): \n",
    "          results = np.concatenate((results, np.array([[format(temp_result/self.no_of_models, \".2f\"), temp_bool]])), axis=0)\n",
    "        else:\n",
    "          results = np.concatenate((results, np.array(temp_bool)))\n",
    "      if print_out:\n",
    "        for result in results: \n",
    "          print(result)\n",
    "      return results\n",
    "    elif isinstance(X, Iterator) or isinstance(X, DirectoryIterator): # For Iterators\n",
    "      results = np.array([])\n",
    "      if steps is None:\n",
    "        steps = ceil(X.n / X.batch_size) # Set number of steps\n",
    "      for i in range(steps): \n",
    "        batch = X.__next__() # Current batch\n",
    "        for j in range(len(self.collections)): # Collect all models vote on the current batch\n",
    "          if j == 0:\n",
    "            temp_result = self._output_interface(self.collections[j].predict(batch)) \n",
    "          else:\n",
    "            temp_result += self._output_interface(self.collections[j].predict(batch)) \n",
    "        temp_bool = (temp_result/self.no_of_models) > 0.5 # Average out the votes\n",
    "        if bool(verbose):\n",
    "          interm = np.stack(((temp_result/self.no_of_models), temp_bool), axis=-1)\n",
    "          results = np.concatenate((results, interm))\n",
    "        else:\n",
    "          results = np.concatenate((results, temp_bool))\n",
    "      if print_out:\n",
    "        for result in results: \n",
    "          print(result)\n",
    "      return results\n",
    "    else:\n",
    "      raise TypeError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bjsi-kImBJCB"
   },
   "source": [
    "#### 1.3 Function to ensemble all the methods \n",
    "\n",
    "Ensembling of all the models, loading of the corresponding fine-tuned weights and returns an ensemble model\n",
    "<br/><br/>\n",
    "___\n",
    "\n",
    "<br/>\n",
    "\n",
    "*collect_model*\n",
    "\n",
    "```python\n",
    "collect_model(\n",
    "    *args, \n",
    "    weights_path\n",
    "    name='Hypermodel 1'\n",
    ")\n",
    "```\n",
    "\n",
    "collect_model() helps to add models to the Hypermodel it returns with their weights loaded\n",
    "\n",
    "__Arguments:__\n",
    "\n",
    "| Parameter | Description |\n",
    "| :--- | :--- |\n",
    "| __\\*args__ | Any number of tuples of the form `(<model instance>, <model output type>)` |\n",
    "| **weights_path** | A list of paths to each model's weights in the same sequence that \\*args is defined |\n",
    "| __name__ | Name for the `Hypermodel` |\n",
    "\n",
    "__Raises:__\n",
    "\n",
    "| Error | Reason |\n",
    "| :--- | :--- |\n",
    "| __TypeError__ | `weights_path` is not a `list` or `*args` are not all `tuples` |\n",
    "\n",
    "__Returns:__\n",
    "\n",
    "| Variable | Description |\n",
    "| :--- | :--- |\n",
    "| __result__ | `Hypermodel` with all the models added to it |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vjkpDPjrBFxk"
   },
   "outputs": [],
   "source": [
    "# 1.3\n",
    "# collect_model() function\n",
    "\n",
    "def collect_model(*args, weights_path, name='Hypermodel 1'):\n",
    "  \"Collects all the models into one Hypermodel instance which is then returned\"\n",
    "  try:\n",
    "    assert isinstance(weights_path, list) # weights_path is a list of strings\n",
    "  except:\n",
    "    raise TypeError\n",
    "  \n",
    "  result = Hypermodel(name) \n",
    "  \n",
    "  counter = 0  \n",
    "  for model, form in args:\n",
    "    model.load_weights(weights_path[counter]) # Load weights of model to be added\n",
    "\n",
    "    result.add_tuple((model, form)) # Adds the model\n",
    "    \n",
    "    counter += 1\n",
    "  \n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage example\n",
    "\n",
    "```python\n",
    "# Weights preparation\n",
    "model_1_weights = \"<path to model 1 weights>\"\n",
    "model_2_weights = \"<path to model 2 weights>\"\n",
    "weights_path = [model_1_weights, model_2_weights]\n",
    "\n",
    "# Forming Hypermodel\n",
    "hypermodel = collect_model(model_1(), model_2(), weights_path=weights_path, name=\"test\")\n",
    "\n",
    "# Prepare Iterator\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "X = datagen.flow_from_directory(\"<path>\", target_size=(224, 224), batch_size=32, class_mode='binary')\n",
    "\n",
    "# Predict\n",
    "results = hypermodel.predict(X)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFrUBBquVhVn"
   },
   "source": [
    "## 2. Using live video feed by integrating with OpenCV \n",
    "\n",
    "Seems there're a few methods to approach the model deployment\n",
    "*  For video detection, we can stream from a webcam, extract region of interest using OpenCV's deep neural network and then detect the presence of mask\n",
    "*  For image detection, a similar approach can be used\n",
    "\n",
    "Seems there're also a few methods to build a face detector with OpenCV\n",
    "*  Using pre-trained models stored as XML docs on OpenCV's github\n",
    "*  Using pre-trained models stored as caffemodel files by Berkley's Caffe Model Zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9E0whVl-VNeY"
   },
   "source": [
    "### 2.1 Function find_mask_in_video() \n",
    "\n",
    "Finds the faces and predicts mask wearing in the video  \n",
    "Mainly a helper function for the code below in 2.2\n",
    "\n",
    "__Arguments:__\n",
    "\n",
    "| Parameter | Description |\n",
    "| :--- | :--- |\n",
    "| __frame__ | Current frame of interest |\n",
    "| **find_face** | The model that detects faces and isolate them as regions of interest |\n",
    "| **find_mask** | The model that detects masks in the regions of interest returned by the model in `find_face` parameter |\n",
    "\n",
    "__Returns:__\n",
    "\n",
    "| Variable | Description |\n",
    "| :--- | :--- |\n",
    "| (__locations__, __predictions__) | A tuple containing a list of locations of regions of interest and a list of their corresponding mask predictions by both models passed in as arguments within the current isolated frame |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4_oLifOW7ps"
   },
   "outputs": [],
   "source": [
    "def find_mask_in_video(frame, find_face, find_mask):\n",
    "  \"\"\"Finds the faces in the frame passed in as its argument, \n",
    "  predicts if a mask is worn for every face and returns the locations and predictions of each face\"\"\"\n",
    "\n",
    "  (height, width) = frame.shape[:2] # height and width of the whole frame\n",
    "  blob = cv2.dnn.blobFromImage(frame, ) # incomplete, find out more on blob\n",
    "\n",
    "  find_face.setInput(blob)\n",
    "  detections = find_face.forward() \n",
    "\n",
    "  faces = [] # pixel information of the face image extracted\n",
    "  locations = [] # location of faces in reference to the frame\n",
    "  predictions = [] # predictions by our mask detection model\n",
    "\n",
    "  for i in range(detections.shape[2]):\n",
    "    box = detections[0, 0, i, 3:7] * np.array([width, height, width, height]) \n",
    "    # detections.shape[0,0,i,3:7] gives four values that \n",
    "    # can be multiplied with the frame heights and widths to get the coordinates of the 'box' around the face detected\n",
    "    start_X, start_Y, end_X, end_Y = box.astype(\"int\")\n",
    "\n",
    "    # ensures all the 'boxes' of faces detected are within frame\n",
    "    start_X, start_Y = (max(0, start_X), max(0, start_Y))\n",
    "    end_X, end_Y = (min(width - 1, end_X), min(height - 1, end_Y))\n",
    "\n",
    "    # extracting the region of interest (ROI) from video frame\n",
    "    face = frame[start_Y:end_Y, start_X:end_X] # extract ROI\n",
    "    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB) # convert color channel from BGR to RGB\n",
    "    face = face.resize(face, (224, 224)) # resize to our target 224, 224\n",
    "    face = img_to_array(face) \n",
    "    face = custom_preprocess_input(face) # incomplete, preprocessing function to customize, necessary to rescale\n",
    "\n",
    "    faces.append(face)\n",
    "    locations.append((start_X, start_Y, end_X, end_Y))\n",
    "  \n",
    "  if len(faces) > 0:\n",
    "    faces = np.array(faces, dtype=\"float32\")\n",
    "    predictions = find_mask.predict(faces, batch_size=32) # returns a list of booleans / a list of tuples, uses the Hypermodel class\n",
    "  \n",
    "  return (locations, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOYAm9LaJudi"
   },
   "source": [
    "### 2.2 Implement the function find_mask_in_video() to a live stream \n",
    "\n",
    "Implements mask detector in a webcam livestream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dbV0aE9mCmZN"
   },
   "outputs": [],
   "source": [
    "# 2.2\n",
    "# Main set of codes that enables the live video mask detection\n",
    "\n",
    "PROTOTXT_PATH = # incomplete, for the OpenCV face detector\n",
    "WEIGHTS_PATH = # incomplete, for the OpenCV face detector\n",
    "\n",
    "face_detector = cv2.dnn.readNet(PROTOTXT_PATH, WEIGHTS_PATH)\n",
    "\n",
    "MASK_WEIGHTS_PATH = # incomplete, weights of our models\n",
    "\n",
    "mask_detector = collect_model(model_1(), model_2(), ..., weights_path=MASK_WEIGHTS_PATH, name=\"Elon Mask\") # incomplete, to fill in models\n",
    "\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)\n",
    "\n",
    "while True:\n",
    "  frame = vs.read() # reads a frame\n",
    "  frame = imutils.resize(frame, width=400) # incomplete, decide on the frame size\n",
    "\n",
    "  locations, predictions = find_mask_in_video(frame, face_detector, mask_detector) # get predictions\n",
    "\n",
    "  for (box, pred) in zip(locations, predictions): # labelling the predictions\n",
    "    (start_X, start_Y, end_X, end_Y) = box\n",
    "    if isinstance(pred, tuple):\n",
    "      mask = pred[1]\n",
    "      prob = pred[0]\n",
    "      if mask:\n",
    "        label = f\"Mask: {(prob * 100):.2f}%\"\n",
    "        color = (0, 255, 0) # videostream uses BGR channels apparently, green\n",
    "      else:\n",
    "        label = f\"No mask: {(prob * 100):.2f}%\"\n",
    "        color = (0, 0, 255) # videostream uses BGR channels apparently, red\n",
    "    else:\n",
    "      if pred: \n",
    "        label = \"Mask\"\n",
    "        color = (0, 255, 0) # videostream uses BGR channels apparently, green\n",
    "      else:\n",
    "        label = \"No mask\"\n",
    "        color = (0, 0, 255) # videostream uses BGR channels apparently, red\n",
    "    \n",
    "    cv2.putText(frame, label, (start_X, start_Y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2) # label\n",
    "    cv2.rectangle(frame, (start_X, start_Y), (end_X, end_Y), color, 2) # colored box to mark out face\n",
    "\n",
    "  cv2.imshow(\"Frame\", frame) # project back to live-feed frame\n",
    "  key = cv2.waitkey(1) & 0xFF # allows for exiting of the program by pressing 'q'\n",
    "  \n",
    "  if key == ord(\"q\"): # captures the 'q' key pressed\n",
    "    break\n",
    "\n",
    "cv2.destroyAllWindows() # close all the video feed windows opened by cv2\n",
    "vs.stop() # stops the video stream"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Z-ABVQJE_jxx",
    "9E0whVl-VNeY",
    "wOYAm9LaJudi",
    "aaHy8jwemwWp",
    "FKLgvKa9W67M"
   ],
   "name": "Back-end\\Webcam Integration Code Stack.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
